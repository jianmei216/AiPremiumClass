{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7bc00c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-30T07:09:51.255256Z",
     "iopub.status.busy": "2025-07-30T07:09:51.254983Z",
     "iopub.status.idle": "2025-07-30T07:09:52.730566Z",
     "shell.execute_reply": "2025-07-30T07:09:52.729532Z"
    },
    "papermill": {
     "duration": 1.480759,
     "end_time": "2025-07-30T07:09:52.732773",
     "exception": false,
     "start_time": "2025-07-30T07:09:51.252014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c1987b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T07:09:52.739501Z",
     "iopub.status.busy": "2025-07-30T07:09:52.738516Z",
     "iopub.status.idle": "2025-07-30T07:10:03.381958Z",
     "shell.execute_reply": "2025-07-30T07:10:03.381133Z"
    },
    "papermill": {
     "duration": 10.647755,
     "end_time": "2025-07-30T07:10:03.383378",
     "exception": false,
     "start_time": "2025-07-30T07:09:52.735623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\r\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: fsspec, evaluate\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2025.5.1\r\n",
      "    Uninstalling fsspec-2025.5.1:\r\n",
      "      Successfully uninstalled fsspec-2025.5.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\r\n",
      "Collecting seqeval\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\r\n",
      "Building wheels for collected packages: seqeval\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=1ef7126823f3bf3f57ef4e8854922a313379830436a119c8ca6007d7acac6be8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\r\n",
      "Successfully built seqeval\r\n",
      "Installing collected packages: seqeval\r\n",
      "Successfully installed seqeval-1.2.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe11727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T07:10:03.390571Z",
     "iopub.status.busy": "2025-07-30T07:10:03.390317Z",
     "iopub.status.idle": "2025-07-30T07:10:03.398873Z",
     "shell.execute_reply": "2025-07-30T07:10:03.398263Z"
    },
    "papermill": {
     "duration": 0.013367,
     "end_time": "2025-07-30T07:10:03.399902",
     "exception": false,
     "start_time": "2025-07-30T07:10:03.386535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hw_02_ner_ddp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hw_02_ner_ddp.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer,DataCollatorForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "import evaluate  # pip install evaluate\n",
    "import seqeval   # pip install seqeval\n",
    "from datasets import load_dataset\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# 设置分布式环境\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "# 清理分布式环境\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "def train(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "    # 数据集\n",
    "    ds = load_dataset('nlhappy/CLUE-NER')\n",
    "    # entity_index\n",
    "    entites = ['O'] + list({'movie', 'name', 'game', 'address', 'position', \\\n",
    "               'company', 'scene', 'book', 'organization', 'government'})\n",
    "    tags = ['O']\n",
    "    for entity in entites[1:]:\n",
    "        tags.append('B-' + entity.upper())\n",
    "        tags.append('I-' + entity.upper())\n",
    "    \n",
    "    entity_index = {entity:i for i, entity in enumerate(entites)}\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')\n",
    "    \n",
    "    def entity_tags_proc(item):\n",
    "        # item即是dataset中记录\n",
    "        text_len = len(item['text'])  # 根据文本长度生成tags列表\n",
    "        tags = [0] * text_len    # 初始值为‘O’\n",
    "        # 遍历实体列表，所有实体类别标记填入tags\n",
    "        entites = item['ents']\n",
    "        for ent in entites:\n",
    "            indices = ent['indices']  # 实体索引\n",
    "            label = ent['label']   # 实体名\n",
    "            tags[indices[0]] = entity_index[label] * 2 - 1\n",
    "            for idx in indices[1:]:\n",
    "                tags[idx] = entity_index[label] * 2\n",
    "        return {'ent_tag': tags}\n",
    "    \n",
    "    # 使用自定义回调函数处理数据集记录\n",
    "    ds1 = ds.map(entity_tags_proc)\n",
    "    \n",
    "    def data_input_proc(item):\n",
    "        # 输入文本先拆分为字符，再转换为模型输入的token索引\n",
    "        batch_texts = [list(text) for text in item['text']]\n",
    "        # 导入拆分为字符的文本列表时，需要设置参数is_split_into_words=True\n",
    "        input_data = tokenizer(batch_texts, truncation=True, add_special_tokens=False, max_length=512, \n",
    "                               is_split_into_words=True, padding='max_length')\n",
    "        input_data['labels'] = [tag + [0] * (512 - len(tag)) for tag in item['ent_tag']]\n",
    "        return input_data\n",
    "        \n",
    "    \n",
    "    ds2 = ds1.map(data_input_proc, batched=True)  # batch_size 1000\n",
    "    \n",
    "    local_rank = rank\n",
    "    \n",
    "    id2lbl = {i:tag for i, tag in enumerate(tags)}\n",
    "    lbl2id = {tag:i for i, tag in enumerate(tags)}\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', \n",
    "                                                            num_labels=21,\n",
    "                                                            id2label=id2lbl,\n",
    "                                                            label2id=lbl2id)\n",
    "    model.to(local_rank)\n",
    "    \n",
    "    # args = TrainingArguments(\n",
    "    #     output_dir=\"ner_train\",  # 模型训练工作目录（tensorboard，临时模型存盘文件，日志）\n",
    "    #     num_train_epochs = 3,    # 训练 epoch\n",
    "    #     save_safetensors=False,  # 设置False保存文件可以通过torch.load加载\n",
    "    #     per_device_train_batch_size=16,  # 训练批次\n",
    "    #     per_device_eval_batch_size=16,\n",
    "    #     eval_strategy=\"epoch\",      # 每个epoch结束后进行评估\n",
    "    #     #save_strategy=\"epoch\",      # 每个epoch结束后保存模型\n",
    "    #     #load_best_model_at_end=True,    # 训练结束后加载最佳模型\n",
    "    #     #metric_for_best_model=\"f1\",     # 使用f1分数作为评判最佳模型的标准\n",
    "    #     #report_to='tensorboard',  # 训练输出记录\n",
    "    #     local_rank=local_rank,   # 当前进程 RANK\n",
    "    #     fp16=True,               # 使用混合精度\n",
    "    #     lr_scheduler_type='linear',  # 动态学习率\n",
    "    #     warmup_steps=100,        # 预热步数\n",
    "    #     ddp_find_unused_parameters=False  # 优化DDP性能\n",
    "    # )\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"ner_train\",  # 模型训练工作目录（tensorboard，临时模型存盘文件，日志）\n",
    "        num_train_epochs = 3,    # 训练 epoch\n",
    "        save_safetensors=False,  # 设置False保存文件可以通过torch.load加载\n",
    "        per_device_train_batch_size=8,  # 训练批次\n",
    "        per_device_eval_batch_size=8,\n",
    "        report_to='tensorboard',  # 训练输出记录\n",
    "        eval_strategy=\"epoch\",\n",
    "        local_rank=local_rank,   # 当前进程 RANK\n",
    "        fp16=True,               # 使用混合精度\n",
    "        lr_scheduler_type='linear',  # 动态学习率\n",
    "        warmup_steps=100,        # 预热步数\n",
    "        ddp_find_unused_parameters=False  # 优化DDP性能\n",
    "    )\n",
    "    \n",
    "    def compute_metric(result):\n",
    "        # result 是一个tuple (predicts, labels)\n",
    "        \n",
    "        # 获取评估对象\n",
    "        seqeval = evaluate.load('seqeval')\n",
    "        predicts,labels = result\n",
    "        predicts = np.argmax(predicts, axis=2)\n",
    "        \n",
    "        # 准备评估数据\n",
    "        predicts = [[tags[p] for p,l in zip(ps,ls) if l != -100]\n",
    "                     for ps,ls in zip(predicts,labels)]\n",
    "        labels = [[tags[l] for p,l in zip(ps,ls) if l != -100]\n",
    "                     for ps,ls in zip(predicts,labels)]\n",
    "        results = seqeval.compute(predictions=predicts, references=labels)\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=ds2['train'],\n",
    "        eval_dataset=ds2['validation'],\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metric\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    # 在trainer.train()之后添加\n",
    "    if rank == 0:  # 只有主进程保存模型\n",
    "        trainer.save_model(\"/kaggle/output/ner_final_model\")  # 保存完整模型\n",
    "        tokenizer.save_pretrained(\"/kaggle/output/ner_final_model\")  # 保存tokenizer\n",
    "\n",
    "def main():\n",
    "    world_size = torch.cuda.device_count()\n",
    "    mp.spawn(train, args=(world_size,), nprocs=world_size, join=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a530382e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T07:10:03.405609Z",
     "iopub.status.busy": "2025-07-30T07:10:03.405436Z",
     "iopub.status.idle": "2025-07-30T08:19:30.665306Z",
     "shell.execute_reply": "2025-07-30T08:19:30.664513Z"
    },
    "papermill": {
     "duration": 4167.264363,
     "end_time": "2025-07-30T08:19:30.666847",
     "exception": false,
     "start_time": "2025-07-30T07:10:03.402484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-30 07:10:13.163042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1753859413.386428      63 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1753859413.449972      63 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2025-07-30 07:10:38.406891: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-07-30 07:10:38.406930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1753859438.428451      78 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1753859438.428604      77 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1753859438.435142      78 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1753859438.435545      77 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "README.md: 100%|██████████████████████████████| 21.0/21.0 [00:00<00:00, 109kB/s]\r\n",
      "dataset_infos.json: 100%|██████████████████████| 970/970 [00:00<00:00, 6.45MB/s]\r\n",
      "data/train-00000-of-00001-a33d0e4276aef9(…): 100%|█| 1.30M/1.30M [00:00<00:00, 1\r\n",
      "data/validation-00000-of-00001-07f476b71(…): 100%|█| 178k/178k [00:00<00:00, 506\r\n",
      "Generating train split: 100%|██| 10748/10748 [00:00<00:00, 165544.97 examples/s]\r\n",
      "Generating validation split: 100%|█| 1343/1343 [00:00<00:00, 321533.78 examples/\r\n",
      "tokenizer_config.json: 100%|██████████████████| 49.0/49.0 [00:00<00:00, 456kB/s]\r\n",
      "config.json: 100%|█████████████████████████████| 624/624 [00:00<00:00, 5.43MB/s]\r\n",
      "vocab.txt: 110kB [00:00, 7.51MB/s]\r\n",
      "tokenizer.json: 269kB [00:00, 21.3MB/s]\r\n",
      "Map: 100%|██████████████████████| 10748/10748 [00:01<00:00, 10304.97 examples/s]\r\n",
      "Map: 100%|██████████████████████| 10748/10748 [00:01<00:00, 10149.27 examples/s]\r\n",
      "Map: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 9927.41 examples/s]\r\n",
      "Map: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 9981.64 examples/s]\r\n",
      "Map: 100%|███████████████████████| 10748/10748 [00:05<00:00, 1871.02 examples/s]\r\n",
      "Map: 100%|███████████████████████| 10748/10748 [00:05<00:00, 1865.22 examples/s]\r\n",
      "Map: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 1950.43 examples/s]\r\n",
      "Map: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 1942.78 examples/s]\r\n",
      "model.safetensors: 100%|██████████████████████| 412M/412M [00:01<00:00, 235MB/s]\r\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\r\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\r\n",
      "  0%|                                                  | 0/2016 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.1179, 'grad_norm': 10841.2802734375, 'learning_rate': 3.9587682672233825e-05, 'epoch': 0.74}\r\n",
      "{'loss': 0.1137, 'grad_norm': 19786.744140625, 'learning_rate': 3.9587682672233825e-05, 'epoch': 0.74}\r\n",
      " 25%|█████████▉                              | 500/2016 [16:00<49:31,  1.96s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      " 33%|█████████████▎                          | 672/2016 [21:41<41:19,  1.85s/it]\r\n",
      "  0%|                                                    | 0/84 [00:00<?, ?it/s]\u001b[A\r\n",
      "  0%|                                                    | 0/84 [00:00<?, ?it/s]\u001b[A\r\n",
      "  2%|█                                           | 2/84 [00:00<00:22,  3.57it/s]\u001b[A\r\n",
      "  2%|█                                           | 2/84 [00:00<00:23,  3.44it/s]\u001b[A\r\n",
      "  4%|█▌                                          | 3/84 [00:01<00:31,  2.54it/s]\u001b[A\r\n",
      "  4%|█▌                                          | 3/84 [00:01<00:34,  2.35it/s]\u001b[A\r\n",
      "  5%|██                                          | 4/84 [00:01<00:36,  2.16it/s]\u001b[A\r\n",
      "  5%|██                                          | 4/84 [00:01<00:38,  2.06it/s]\u001b[A\r\n",
      "  6%|██▌                                         | 5/84 [00:02<00:39,  1.99it/s]\u001b[A\r\n",
      "  6%|██▌                                         | 5/84 [00:02<00:41,  1.93it/s]\u001b[A\r\n",
      "  7%|███▏                                        | 6/84 [00:02<00:41,  1.89it/s]\u001b[A\r\n",
      "  7%|███▏                                        | 6/84 [00:02<00:42,  1.84it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 7/84 [00:03<00:41,  1.88it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 7/84 [00:03<00:44,  1.74it/s]\u001b[A\r\n",
      " 10%|████▏                                       | 8/84 [00:03<00:41,  1.82it/s]\u001b[A\r\n",
      " 10%|████▏                                       | 8/84 [00:04<00:43,  1.74it/s]\u001b[A\r\n",
      " 11%|████▋                                       | 9/84 [00:04<00:41,  1.79it/s]\u001b[A\r\n",
      " 11%|████▋                                       | 9/84 [00:04<00:43,  1.74it/s]\u001b[A\r\n",
      " 12%|█████                                      | 10/84 [00:05<00:41,  1.77it/s]\u001b[A\r\n",
      " 12%|█████                                      | 10/84 [00:05<00:42,  1.73it/s]\u001b[A\r\n",
      " 13%|█████▋                                     | 11/84 [00:05<00:41,  1.76it/s]\u001b[A\r\n",
      " 13%|█████▋                                     | 11/84 [00:05<00:42,  1.73it/s]\u001b[A\r\n",
      " 14%|██████▏                                    | 12/84 [00:06<00:40,  1.76it/s]\u001b[A\r\n",
      " 14%|██████▏                                    | 12/84 [00:06<00:41,  1.73it/s]\u001b[A\r\n",
      " 15%|██████▋                                    | 13/84 [00:06<00:40,  1.75it/s]\u001b[A\r\n",
      " 15%|██████▋                                    | 13/84 [00:07<00:41,  1.73it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 14/84 [00:07<00:40,  1.75it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 14/84 [00:07<00:40,  1.73it/s]\u001b[A\r\n",
      " 18%|███████▋                                   | 15/84 [00:08<00:39,  1.74it/s]\u001b[A\r\n",
      " 18%|███████▋                                   | 15/84 [00:08<00:39,  1.74it/s]\u001b[A\r\n",
      " 19%|████████▏                                  | 16/84 [00:08<00:39,  1.74it/s]\u001b[A\r\n",
      " 19%|████████▏                                  | 16/84 [00:08<00:38,  1.74it/s]\u001b[A\r\n",
      " 20%|████████▋                                  | 17/84 [00:09<00:38,  1.74it/s]\u001b[A\r\n",
      " 20%|████████▋                                  | 17/84 [00:09<00:38,  1.74it/s]\u001b[A\r\n",
      " 21%|█████████▏                                 | 18/84 [00:09<00:38,  1.74it/s]\u001b[A\r\n",
      " 21%|█████████▏                                 | 18/84 [00:09<00:37,  1.74it/s]\u001b[A\r\n",
      " 23%|█████████▋                                 | 19/84 [00:10<00:37,  1.73it/s]\u001b[A\r\n",
      " 23%|█████████▋                                 | 19/84 [00:10<00:37,  1.73it/s]\u001b[A\r\n",
      " 24%|██████████▏                                | 20/84 [00:10<00:36,  1.74it/s]\u001b[A\r\n",
      " 24%|██████████▏                                | 20/84 [00:11<00:36,  1.74it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 21/84 [00:11<00:36,  1.74it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 21/84 [00:11<00:36,  1.73it/s]\u001b[A\r\n",
      " 26%|███████████▎                               | 22/84 [00:12<00:35,  1.74it/s]\u001b[A\r\n",
      " 26%|███████████▎                               | 22/84 [00:12<00:35,  1.74it/s]\u001b[A\r\n",
      " 27%|███████████▊                               | 23/84 [00:12<00:35,  1.73it/s]\u001b[A\r\n",
      " 27%|███████████▊                               | 23/84 [00:12<00:34,  1.75it/s]\u001b[A\r\n",
      " 29%|████████████▎                              | 24/84 [00:13<00:34,  1.72it/s]\u001b[A\r\n",
      " 29%|████████████▎                              | 24/84 [00:13<00:34,  1.74it/s]\u001b[A\r\n",
      " 30%|████████████▊                              | 25/84 [00:13<00:33,  1.74it/s]\u001b[A\r\n",
      " 30%|████████████▊                              | 25/84 [00:13<00:34,  1.71it/s]\u001b[A\r\n",
      " 31%|█████████████▎                             | 26/84 [00:14<00:33,  1.75it/s]\u001b[A\r\n",
      " 31%|█████████████▎                             | 26/84 [00:14<00:33,  1.72it/s]\u001b[A\r\n",
      " 32%|█████████████▊                             | 27/84 [00:14<00:32,  1.73it/s]\u001b[A\r\n",
      " 32%|█████████████▊                             | 27/84 [00:15<00:32,  1.74it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 28/84 [00:15<00:32,  1.74it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 28/84 [00:15<00:32,  1.75it/s]\u001b[A\r\n",
      " 35%|██████████████▊                            | 29/84 [00:16<00:31,  1.73it/s]\u001b[A\r\n",
      " 35%|██████████████▊                            | 29/84 [00:16<00:31,  1.74it/s]\u001b[A\r\n",
      " 36%|███████████████▎                           | 30/84 [00:16<00:31,  1.74it/s]\u001b[A\r\n",
      " 36%|███████████████▎                           | 30/84 [00:16<00:31,  1.74it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 31/84 [00:17<00:30,  1.73it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 31/84 [00:17<00:30,  1.73it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 32/84 [00:17<00:29,  1.73it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 32/84 [00:18<00:29,  1.74it/s]\u001b[A\r\n",
      " 39%|████████████████▉                          | 33/84 [00:18<00:29,  1.74it/s]\u001b[A\r\n",
      " 39%|████████████████▉                          | 33/84 [00:18<00:29,  1.73it/s]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 34/84 [00:18<00:28,  1.73it/s]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 34/84 [00:19<00:28,  1.74it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 35/84 [00:19<00:28,  1.73it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 35/84 [00:19<00:28,  1.74it/s]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 36/84 [00:20<00:27,  1.73it/s]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 36/84 [00:20<00:27,  1.73it/s]\u001b[A\r\n",
      " 44%|██████████████████▉                        | 37/84 [00:20<00:27,  1.73it/s]\u001b[A\r\n",
      " 44%|██████████████████▉                        | 37/84 [00:20<00:27,  1.73it/s]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 38/84 [00:21<00:26,  1.72it/s]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 38/84 [00:21<00:26,  1.73it/s]\u001b[A\r\n",
      " 46%|███████████████████▉                       | 39/84 [00:21<00:25,  1.73it/s]\u001b[A\r\n",
      " 46%|███████████████████▉                       | 39/84 [00:22<00:25,  1.74it/s]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 40/84 [00:22<00:25,  1.74it/s]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 40/84 [00:22<00:25,  1.73it/s]\u001b[A\r\n",
      " 49%|████████████████████▉                      | 41/84 [00:23<00:24,  1.73it/s]\u001b[A\r\n",
      " 49%|████████████████████▉                      | 41/84 [00:23<00:24,  1.73it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 42/84 [00:23<00:24,  1.73it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 42/84 [00:23<00:24,  1.73it/s]\u001b[A\r\n",
      " 51%|██████████████████████                     | 43/84 [00:24<00:23,  1.73it/s]\u001b[A\r\n",
      " 51%|██████████████████████                     | 43/84 [00:24<00:23,  1.74it/s]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 44/84 [00:24<00:23,  1.74it/s]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 44/84 [00:24<00:23,  1.73it/s]\u001b[A\r\n",
      " 54%|███████████████████████                    | 45/84 [00:25<00:22,  1.74it/s]\u001b[A\r\n",
      " 54%|███████████████████████                    | 45/84 [00:25<00:22,  1.74it/s]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 46/84 [00:25<00:21,  1.74it/s]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 46/84 [00:26<00:21,  1.73it/s]\u001b[A\r\n",
      " 56%|████████████████████████                   | 47/84 [00:26<00:21,  1.73it/s]\u001b[A\r\n",
      " 56%|████████████████████████                   | 47/84 [00:26<00:21,  1.73it/s]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 48/84 [00:27<00:20,  1.74it/s]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 48/84 [00:27<00:20,  1.72it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 49/84 [00:27<00:20,  1.74it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 49/84 [00:27<00:20,  1.74it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 50/84 [00:28<00:19,  1.73it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 50/84 [00:28<00:19,  1.73it/s]\u001b[A\r\n",
      " 61%|██████████████████████████                 | 51/84 [00:28<00:19,  1.73it/s]\u001b[A\r\n",
      " 61%|██████████████████████████                 | 51/84 [00:28<00:19,  1.73it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 52/84 [00:29<00:18,  1.73it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 52/84 [00:29<00:18,  1.73it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 53/84 [00:29<00:17,  1.73it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 53/84 [00:30<00:17,  1.74it/s]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 54/84 [00:30<00:17,  1.73it/s]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 54/84 [00:30<00:17,  1.74it/s]\u001b[A\r\n",
      " 65%|████████████████████████████▏              | 55/84 [00:31<00:16,  1.73it/s]\u001b[A\r\n",
      " 65%|████████████████████████████▏              | 55/84 [00:31<00:16,  1.74it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 56/84 [00:31<00:16,  1.73it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 56/84 [00:31<00:16,  1.75it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▏             | 57/84 [00:32<00:15,  1.74it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▏             | 57/84 [00:32<00:15,  1.73it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 58/84 [00:32<00:14,  1.74it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 58/84 [00:33<00:15,  1.73it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████▏            | 59/84 [00:33<00:14,  1.73it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████▏            | 59/84 [00:33<00:14,  1.74it/s]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 60/84 [00:33<00:13,  1.73it/s]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 60/84 [00:34<00:13,  1.73it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▏           | 61/84 [00:34<00:13,  1.73it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▏           | 61/84 [00:34<00:13,  1.73it/s]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 62/84 [00:35<00:12,  1.73it/s]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 62/84 [00:35<00:12,  1.73it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 63/84 [00:35<00:12,  1.73it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 63/84 [00:35<00:12,  1.73it/s]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 64/84 [00:36<00:11,  1.73it/s]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 64/84 [00:36<00:11,  1.73it/s]\u001b[A\r\n",
      " 77%|█████████████████████████████████▎         | 65/84 [00:36<00:10,  1.73it/s]\u001b[A\r\n",
      " 77%|█████████████████████████████████▎         | 65/84 [00:37<00:11,  1.73it/s]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 66/84 [00:37<00:10,  1.73it/s]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 66/84 [00:37<00:10,  1.73it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▎        | 67/84 [00:38<00:09,  1.73it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▎        | 67/84 [00:38<00:09,  1.73it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 68/84 [00:38<00:09,  1.73it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 68/84 [00:38<00:09,  1.73it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████▎       | 69/84 [00:39<00:08,  1.73it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████▎       | 69/84 [00:39<00:08,  1.74it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 70/84 [00:39<00:08,  1.73it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 70/84 [00:39<00:08,  1.75it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▎      | 71/84 [00:40<00:07,  1.74it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▎      | 71/84 [00:40<00:07,  1.74it/s]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 72/84 [00:40<00:06,  1.74it/s]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 72/84 [00:41<00:06,  1.74it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 73/84 [00:41<00:06,  1.73it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 73/84 [00:41<00:06,  1.72it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 74/84 [00:42<00:05,  1.73it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 74/84 [00:42<00:05,  1.73it/s]\u001b[A\r\n",
      " 89%|██████████████████████████████████████▍    | 75/84 [00:42<00:05,  1.73it/s]\u001b[A\r\n",
      " 89%|██████████████████████████████████████▍    | 75/84 [00:42<00:05,  1.75it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 76/84 [00:43<00:04,  1.71it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 76/84 [00:43<00:04,  1.81it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 77/84 [00:43<00:03,  1.97it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 77/84 [00:44<00:04,  1.50it/s]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 78/84 [00:44<00:03,  1.88it/s]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 78/84 [00:44<00:03,  1.56it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▍  | 79/84 [00:44<00:02,  1.84it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▍  | 79/84 [00:45<00:03,  1.61it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 80/84 [00:45<00:02,  1.81it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 80/84 [00:45<00:02,  1.64it/s]\u001b[A\r\n",
      " 96%|█████████████████████████████████████████▍ | 81/84 [00:46<00:01,  1.78it/s]\u001b[A\r\n",
      " 96%|█████████████████████████████████████████▍ | 81/84 [00:46<00:01,  1.67it/s]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 82/84 [00:46<00:01,  1.78it/s]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 82/84 [00:46<00:01,  1.69it/s]\u001b[A\r\n",
      " 99%|██████████████████████████████████████████▍| 83/84 [00:47<00:00,  1.75it/s]\u001b[A\r\n",
      " 99%|██████████████████████████████████████████▍| 83/84 [00:47<00:00,  1.69it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:47<00:00,  1.74it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:48<00:00,  1.84it/s]\u001b[A\r\n",
      "\r\n",
      "Downloading builder script: 6.34kB [00:00, 17.0MB/s]\r\n",
      "\r\n",
      "\r\n",
      "Downloading builder script: 6.34kB [00:00, 16.7MB/s]\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5149253731343284, 'recall': 0.5549597855227882, 'f1': 0.5341935483870969, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6086956521739131, 'recall': 0.8181818181818182, 'f1': 0.6980609418282548, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6651685393258427, 'recall': 0.783068783068783, 'f1': 0.7193195625759417, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7146974063400576, 'recall': 0.8406779661016949, 'f1': 0.7725856697819314, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6836734693877551, 'recall': 0.8137651821862348, 'f1': 0.7430683918669131, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7226890756302521, 'recall': 0.5695364238410596, 'f1': 0.6370370370370371, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8249496981891348, 'recall': 0.8817204301075269, 'f1': 0.8523908523908523, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6293103448275862, 'recall': 0.7956403269754768, 'f1': 0.7027677496991576, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7003891050583657, 'recall': 0.8314087759815243, 'f1': 0.7602956705385429, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5923344947735192, 'recall': 0.8133971291866029, 'f1': 0.6854838709677419, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.017066920176148415, 'eval_ADDRESS': {'precision': 0.5149253731343284, 'recall': 0.5549597855227882, 'f1': 0.5341935483870969, 'number': 373}, 'eval_BOOK': {'precision': 0.6086956521739131, 'recall': 0.8181818181818182, 'f1': 0.6980609418282548, 'number': 154}, 'eval_COMPANY': {'precision': 0.6651685393258427, 'recall': 0.783068783068783, 'f1': 0.7193195625759417, 'number': 378}, 'eval_GAME': {'precision': 0.7146974063400576, 'recall': 0.8406779661016949, 'f1': 0.7725856697819314, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.6836734693877551, 'recall': 0.8137651821862348, 'f1': 0.7430683918669131, 'number': 247}, 'eval_MOVIE': {'precision': 0.7226890756302521, 'recall': 0.5695364238410596, 'f1': 0.6370370370370371, 'number': 151}, 'eval_NAME': {'precision': 0.8249496981891348, 'recall': 0.8817204301075269, 'f1': 0.8523908523908523, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.6293103448275862, 'recall': 0.7956403269754768, 'f1': 0.7027677496991576, 'number': 367}, 'eval_POSITION': {'precision': 0.7003891050583657, 'recall': 0.8314087759815243, 'f1': 0.7602956705385429, 'number': 433}, 'eval_SCENE': {'precision': 0.5923344947735192, 'recall': 0.8133971291866029, 'f1': 0.6854838709677419, 'number': 209}, 'eval_overall_precision': 0.6700223713646533, 'eval_overall_recall': 0.7799479166666666, 'eval_overall_f1': 0.7208182912154031, 'eval_overall_accuracy': 0.9948968610387193, 'eval_runtime': 55.2485, 'eval_samples_per_second': 24.308, 'eval_steps_per_second': 1.52, 'epoch': 1.0}\r\n",
      " 33%|█████████████▎                          | 672/2016 [22:36<41:19,  1.85s/it]\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:54<00:00,  1.74it/s]\u001b[A\r\n",
      " 33%|████████████▋                         | 673/2016 [22:37<6:46:16, 18.15s/it]Trainer is attempting to log a value of \"{'precision': 0.5233644859813084, 'recall': 0.6005361930294906, 'f1': 0.5593008739076154, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6721311475409836, 'recall': 0.7987012987012987, 'f1': 0.7299703264094956, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7050359712230215, 'recall': 0.7777777777777778, 'f1': 0.7396226415094339, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7008547008547008, 'recall': 0.8338983050847457, 'f1': 0.761609907120743, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.656140350877193, 'recall': 0.757085020242915, 'f1': 0.7030075187969924, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6946564885496184, 'recall': 0.6026490066225165, 'f1': 0.6453900709219857, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7887596899224806, 'recall': 0.875268817204301, 'f1': 0.8297655453618756, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6274509803921569, 'recall': 0.784741144414169, 'f1': 0.6973365617433415, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6666666666666666, 'recall': 0.836027713625866, 'f1': 0.7418032786885247, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6428571428571429, 'recall': 0.8181818181818182, 'f1': 0.7200000000000001, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.01705259457230568, 'eval_ADDRESS': {'precision': 0.5233644859813084, 'recall': 0.6005361930294906, 'f1': 0.5593008739076154, 'number': 373}, 'eval_BOOK': {'precision': 0.6721311475409836, 'recall': 0.7987012987012987, 'f1': 0.7299703264094956, 'number': 154}, 'eval_COMPANY': {'precision': 0.7050359712230215, 'recall': 0.7777777777777778, 'f1': 0.7396226415094339, 'number': 378}, 'eval_GAME': {'precision': 0.7008547008547008, 'recall': 0.8338983050847457, 'f1': 0.761609907120743, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.656140350877193, 'recall': 0.757085020242915, 'f1': 0.7030075187969924, 'number': 247}, 'eval_MOVIE': {'precision': 0.6946564885496184, 'recall': 0.6026490066225165, 'f1': 0.6453900709219857, 'number': 151}, 'eval_NAME': {'precision': 0.7887596899224806, 'recall': 0.875268817204301, 'f1': 0.8297655453618756, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.6274509803921569, 'recall': 0.784741144414169, 'f1': 0.6973365617433415, 'number': 367}, 'eval_POSITION': {'precision': 0.6666666666666666, 'recall': 0.836027713625866, 'f1': 0.7418032786885247, 'number': 433}, 'eval_SCENE': {'precision': 0.6428571428571429, 'recall': 0.8181818181818182, 'f1': 0.7200000000000001, 'number': 209}, 'eval_overall_precision': 0.668622520257055, 'eval_overall_recall': 0.7789713541666666, 'eval_overall_f1': 0.7195910389415124, 'eval_overall_accuracy': 0.9949390357408786, 'eval_runtime': 56.5992, 'eval_samples_per_second': 23.728, 'eval_steps_per_second': 1.484, 'epoch': 1.0}\r\n",
      " 33%|█████████████▎                          | 672/2016 [22:37<41:43,  1.86s/it]\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:55<00:00,  1.84it/s]\u001b[A\r\n",
      "{'loss': 0.0153, 'grad_norm': 9627.015625, 'learning_rate': 2.6539665970772443e-05, 'epoch': 1.49}\r\n",
      "{'loss': 0.0154, 'grad_norm': 15550.64453125, 'learning_rate': 2.6539665970772443e-05, 'epoch': 1.49}\r\n",
      " 50%|███████████████████▎                   | 1000/2016 [33:19<27:56,  1.65s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      " 50%|███████████████████▍                   | 1002/2016 [33:22<30:33,  1.81s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      " 67%|█████████████████████████▉             | 1341/2016 [44:32<22:00,  1.96s/it]\r\n",
      "  0%|                                                    | 0/84 [00:00<?, ?it/s]\u001b[A\r\n",
      "  2%|█                                           | 2/84 [00:00<00:25,  3.21it/s]\u001b[A\r\n",
      " 67%|█████████████████████████▉             | 1342/2016 [44:34<22:04,  1.97s/it]\r\n",
      "  5%|██                                          | 4/84 [00:01<00:37,  2.11it/s]\u001b[A\r\n",
      "  6%|██▌                                         | 5/84 [00:02<00:41,  1.89it/s]\u001b[A\r\n",
      " 67%|█████████████████████████▉             | 1343/2016 [44:36<22:06,  1.97s/it]\r\n",
      "  8%|███▋                                        | 7/84 [00:03<00:43,  1.75it/s]\u001b[A\r\n",
      " 67%|██████████████████████████             | 1344/2016 [44:38<20:24,  1.82s/it]\r\n",
      " 11%|████▋                                       | 9/84 [00:04<00:47,  1.59it/s]\u001b[A\r\n",
      "  0%|                                                    | 0/84 [00:00<?, ?it/s]\u001b[A\r\n",
      " 12%|█████                                      | 10/84 [00:05<00:46,  1.59it/s]\u001b[A\r\n",
      "  2%|█                                           | 2/84 [00:00<00:25,  3.19it/s]\u001b[A\r\n",
      " 13%|█████▋                                     | 11/84 [00:06<00:45,  1.59it/s]\u001b[A\r\n",
      "  4%|█▌                                          | 3/84 [00:01<00:36,  2.24it/s]\u001b[A\r\n",
      " 14%|██████▏                                    | 12/84 [00:06<00:45,  1.59it/s]\u001b[A\r\n",
      "\r\n",
      " 15%|██████▋                                    | 13/84 [00:07<00:44,  1.59it/s]\u001b[A\r\n",
      "  6%|██▌                                         | 5/84 [00:02<00:43,  1.81it/s]\r\n",
      " 17%|███████▏                                   | 14/84 [00:08<00:43,  1.59it/s]\u001b[A\r\n",
      " 18%|███████▋                                   | 15/84 [00:08<00:43,  1.59it/s]\u001b[A\r\n",
      "  7%|███▏                                        | 6/84 [00:03<00:45,  1.73it/s]\u001b[A\r\n",
      " 19%|████████▏                                  | 16/84 [00:09<00:42,  1.59it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 7/84 [00:03<00:45,  1.68it/s]\u001b[A\r\n",
      " 20%|████████▋                                  | 17/84 [00:10<00:42,  1.59it/s]\u001b[A\r\n",
      " 10%|████▏                                       | 8/84 [00:04<00:46,  1.65it/s]\u001b[A\r\n",
      " 21%|█████████▏                                 | 18/84 [00:10<00:41,  1.59it/s]\u001b[A\r\n",
      " 11%|████▋                                       | 9/84 [00:05<00:46,  1.63it/s]\u001b[A\r\n",
      " 23%|█████████▋                                 | 19/84 [00:11<00:40,  1.59it/s]\u001b[A\r\n",
      " 12%|█████                                      | 10/84 [00:05<00:45,  1.62it/s]\u001b[A\r\n",
      " 24%|██████████▏                                | 20/84 [00:11<00:40,  1.59it/s]\u001b[A\r\n",
      " 13%|█████▋                                     | 11/84 [00:06<00:45,  1.61it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 21/84 [00:12<00:39,  1.59it/s]\u001b[A\r\n",
      " 14%|██████▏                                    | 12/84 [00:06<00:44,  1.60it/s]\u001b[A\r\n",
      " 26%|███████████▎                               | 22/84 [00:13<00:39,  1.59it/s]\u001b[A\r\n",
      " 15%|██████▋                                    | 13/84 [00:07<00:44,  1.60it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 14/84 [00:08<00:43,  1.59it/s]\u001b[A\r\n",
      " 27%|███████████▊                               | 23/84 [00:13<00:38,  1.59it/s]\u001b[A\r\n",
      " 29%|████████████▎                              | 24/84 [00:14<00:37,  1.59it/s]\u001b[A\r\n",
      " 18%|███████▋                                   | 15/84 [00:08<00:43,  1.60it/s]\u001b[A\r\n",
      "\r\n",
      " 19%|████████▏                                  | 16/84 [00:09<00:42,  1.59it/s]\u001b[A\r\n",
      " 31%|█████████████▎                             | 26/84 [00:15<00:36,  1.59it/s]\u001b[A\r\n",
      " 20%|████████▋                                  | 17/84 [00:10<00:42,  1.59it/s]\u001b[A\r\n",
      " 32%|█████████████▊                             | 27/84 [00:16<00:35,  1.59it/s]\u001b[A\r\n",
      " 21%|█████████▏                                 | 18/84 [00:10<00:41,  1.59it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 28/84 [00:16<00:35,  1.59it/s]\u001b[A\r\n",
      " 23%|█████████▋                                 | 19/84 [00:11<00:40,  1.59it/s]\u001b[A\r\n",
      " 35%|██████████████▊                            | 29/84 [00:17<00:34,  1.59it/s]\u001b[A\r\n",
      " 24%|██████████▏                                | 20/84 [00:11<00:40,  1.59it/s]\u001b[A\r\n",
      " 36%|███████████████▎                           | 30/84 [00:18<00:33,  1.59it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 21/84 [00:12<00:39,  1.59it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 31/84 [00:18<00:33,  1.59it/s]\u001b[A\r\n",
      " 26%|███████████▎                               | 22/84 [00:13<00:39,  1.59it/s]\u001b[A\r\n",
      "\r\n",
      " 27%|███████████▊                               | 23/84 [00:13<00:38,  1.58it/s]\u001b[A\r\n",
      " 39%|████████████████▉                          | 33/84 [00:20<00:32,  1.58it/s]\u001b[A\r\n",
      " 29%|████████████▎                              | 24/84 [00:14<00:37,  1.58it/s]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 34/84 [00:20<00:31,  1.58it/s]\u001b[A\r\n",
      " 30%|████████████▊                              | 25/84 [00:15<00:37,  1.58it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 35/84 [00:21<00:30,  1.58it/s]\u001b[A\r\n",
      " 31%|█████████████▎                             | 26/84 [00:15<00:36,  1.58it/s]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 36/84 [00:22<00:30,  1.58it/s]\u001b[A\r\n",
      " 32%|█████████████▊                             | 27/84 [00:16<00:35,  1.58it/s]\u001b[A\r\n",
      " 44%|██████████████████▉                        | 37/84 [00:22<00:25,  1.84it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 28/84 [00:17<00:39,  1.43it/s]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 38/84 [00:22<00:25,  1.78it/s]\u001b[A\r\n",
      " 35%|██████████████▊                            | 29/84 [00:17<00:36,  1.52it/s]\u001b[A\r\n",
      " 46%|███████████████████▉                       | 39/84 [00:23<00:25,  1.75it/s]\u001b[A\r\n",
      " 36%|███████████████▎                           | 30/84 [00:18<00:33,  1.60it/s]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 40/84 [00:24<00:26,  1.68it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 31/84 [00:18<00:31,  1.66it/s]\u001b[A\r\n",
      " 49%|████████████████████▉                      | 41/84 [00:24<00:26,  1.63it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 32/84 [00:19<00:31,  1.67it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 42/84 [00:25<00:25,  1.66it/s]\u001b[A\r\n",
      " 39%|████████████████▉                          | 33/84 [00:20<00:30,  1.68it/s]\u001b[A\r\n",
      " 51%|██████████████████████                     | 43/84 [00:26<00:24,  1.68it/s]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 34/84 [00:20<00:29,  1.68it/s]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 44/84 [00:26<00:23,  1.70it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 35/84 [00:21<00:28,  1.69it/s]\u001b[A\r\n",
      " 54%|███████████████████████                    | 45/84 [00:27<00:23,  1.69it/s]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 36/84 [00:21<00:28,  1.70it/s]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 46/84 [00:27<00:22,  1.70it/s]\u001b[A\r\n",
      " 44%|██████████████████▉                        | 37/84 [00:22<00:27,  1.70it/s]\u001b[A\r\n",
      " 56%|████████████████████████                   | 47/84 [00:28<00:21,  1.70it/s]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 38/84 [00:23<00:27,  1.70it/s]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 48/84 [00:28<00:21,  1.70it/s]\u001b[A\r\n",
      " 46%|███████████████████▉                       | 39/84 [00:23<00:26,  1.71it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 49/84 [00:29<00:20,  1.71it/s]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 40/84 [00:24<00:25,  1.70it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 50/84 [00:30<00:19,  1.71it/s]\u001b[A\r\n",
      " 49%|████████████████████▉                      | 41/84 [00:24<00:25,  1.70it/s]\u001b[A\r\n",
      " 61%|██████████████████████████                 | 51/84 [00:30<00:19,  1.71it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 42/84 [00:25<00:24,  1.71it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 52/84 [00:31<00:18,  1.70it/s]\u001b[A\r\n",
      " 51%|██████████████████████                     | 43/84 [00:25<00:23,  1.71it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 53/84 [00:31<00:18,  1.71it/s]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 44/84 [00:26<00:23,  1.71it/s]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 54/84 [00:32<00:17,  1.72it/s]\u001b[A\r\n",
      " 54%|███████████████████████                    | 45/84 [00:27<00:22,  1.71it/s]\u001b[A\r\n",
      " 65%|████████████████████████████▏              | 55/84 [00:33<00:16,  1.71it/s]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 46/84 [00:27<00:22,  1.72it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 56/84 [00:33<00:16,  1.71it/s]\u001b[A\r\n",
      " 56%|████████████████████████                   | 47/84 [00:28<00:21,  1.72it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▏             | 57/84 [00:34<00:15,  1.71it/s]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 48/84 [00:28<00:20,  1.72it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 58/84 [00:34<00:15,  1.72it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 49/84 [00:29<00:20,  1.71it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████▏            | 59/84 [00:35<00:14,  1.71it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 50/84 [00:30<00:19,  1.71it/s]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 60/84 [00:35<00:14,  1.71it/s]\u001b[A\r\n",
      " 61%|██████████████████████████                 | 51/84 [00:30<00:19,  1.71it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▏           | 61/84 [00:36<00:13,  1.71it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 52/84 [00:31<00:18,  1.71it/s]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 62/84 [00:37<00:12,  1.70it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 53/84 [00:31<00:18,  1.71it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 63/84 [00:37<00:12,  1.70it/s]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 54/84 [00:32<00:17,  1.70it/s]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 64/84 [00:38<00:11,  1.71it/s]\u001b[A\r\n",
      " 65%|████████████████████████████▏              | 55/84 [00:32<00:16,  1.71it/s]\u001b[A\r\n",
      " 77%|█████████████████████████████████▎         | 65/84 [00:38<00:11,  1.71it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 56/84 [00:33<00:16,  1.71it/s]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 66/84 [00:39<00:10,  1.71it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▏             | 57/84 [00:34<00:15,  1.71it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▎        | 67/84 [00:40<00:09,  1.72it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 58/84 [00:34<00:15,  1.71it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 68/84 [00:40<00:09,  1.71it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████▏            | 59/84 [00:35<00:14,  1.72it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████▎       | 69/84 [00:41<00:08,  1.71it/s]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 60/84 [00:35<00:13,  1.73it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 70/84 [00:41<00:08,  1.70it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▏           | 61/84 [00:36<00:13,  1.72it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▎      | 71/84 [00:42<00:07,  1.71it/s]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 62/84 [00:37<00:12,  1.71it/s]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 72/84 [00:42<00:07,  1.71it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 63/84 [00:37<00:12,  1.72it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 73/84 [00:43<00:06,  1.71it/s]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 64/84 [00:38<00:11,  1.71it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 74/84 [00:44<00:05,  1.72it/s]\u001b[A\r\n",
      " 77%|█████████████████████████████████▎         | 65/84 [00:38<00:11,  1.71it/s]\u001b[A\r\n",
      " 89%|██████████████████████████████████████▍    | 75/84 [00:44<00:05,  1.72it/s]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 66/84 [00:39<00:10,  1.71it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 76/84 [00:45<00:04,  1.72it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▎        | 67/84 [00:39<00:09,  1.71it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 77/84 [00:45<00:04,  1.72it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 68/84 [00:40<00:09,  1.71it/s]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 78/84 [00:46<00:03,  1.71it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████▎       | 69/84 [00:41<00:08,  1.72it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▍  | 79/84 [00:47<00:02,  1.71it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 70/84 [00:41<00:08,  1.72it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 80/84 [00:47<00:02,  1.71it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▎      | 71/84 [00:42<00:07,  1.71it/s]\u001b[A\r\n",
      " 96%|█████████████████████████████████████████▍ | 81/84 [00:48<00:01,  1.72it/s]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 72/84 [00:42<00:06,  1.71it/s]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 82/84 [00:48<00:01,  1.72it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 73/84 [00:43<00:06,  1.71it/s]\u001b[A\r\n",
      " 99%|██████████████████████████████████████████▍| 83/84 [00:49<00:00,  1.71it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 74/84 [00:44<00:05,  1.69it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:49<00:00,  1.72it/s]\u001b[A\r\n",
      " 89%|██████████████████████████████████████▍    | 75/84 [00:44<00:04,  1.84it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 76/84 [00:44<00:03,  2.13it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 77/84 [00:45<00:02,  2.40it/s]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 78/84 [00:45<00:02,  2.62it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▍  | 79/84 [00:45<00:01,  2.81it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 80/84 [00:45<00:01,  2.97it/s]\u001b[A\r\n",
      " 96%|█████████████████████████████████████████▍ | 81/84 [00:46<00:00,  3.09it/s]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 82/84 [00:46<00:00,  3.18it/s]\u001b[A\r\n",
      " 99%|██████████████████████████████████████████▍| 83/84 [00:46<00:00,  3.23it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:47<00:00,  3.35it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.54421768707483, 'recall': 0.6434316353887399, 'f1': 0.5896805896805897, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7391304347826086, 'recall': 0.7727272727272727, 'f1': 0.7555555555555555, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7333333333333333, 'recall': 0.8148148148148148, 'f1': 0.7719298245614035, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7569230769230769, 'recall': 0.8338983050847457, 'f1': 0.7935483870967741, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6739130434782609, 'recall': 0.8785425101214575, 'f1': 0.7627416520210897, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7547169811320755, 'recall': 0.7947019867549668, 'f1': 0.7741935483870969, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8302658486707567, 'recall': 0.8731182795698925, 'f1': 0.8511530398322851, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.675609756097561, 'recall': 0.7547683923705722, 'f1': 0.7129987129987131, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7181069958847737, 'recall': 0.8060046189376443, 'f1': 0.7595212187159956, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6387665198237885, 'recall': 0.69377990430622, 'f1': 0.665137614678899, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.015710510313510895, 'eval_ADDRESS': {'precision': 0.54421768707483, 'recall': 0.6434316353887399, 'f1': 0.5896805896805897, 'number': 373}, 'eval_BOOK': {'precision': 0.7391304347826086, 'recall': 0.7727272727272727, 'f1': 0.7555555555555555, 'number': 154}, 'eval_COMPANY': {'precision': 0.7333333333333333, 'recall': 0.8148148148148148, 'f1': 0.7719298245614035, 'number': 378}, 'eval_GAME': {'precision': 0.7569230769230769, 'recall': 0.8338983050847457, 'f1': 0.7935483870967741, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.6739130434782609, 'recall': 0.8785425101214575, 'f1': 0.7627416520210897, 'number': 247}, 'eval_MOVIE': {'precision': 0.7547169811320755, 'recall': 0.7947019867549668, 'f1': 0.7741935483870969, 'number': 151}, 'eval_NAME': {'precision': 0.8302658486707567, 'recall': 0.8731182795698925, 'f1': 0.8511530398322851, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.675609756097561, 'recall': 0.7547683923705722, 'f1': 0.7129987129987131, 'number': 367}, 'eval_POSITION': {'precision': 0.7181069958847737, 'recall': 0.8060046189376443, 'f1': 0.7595212187159956, 'number': 433}, 'eval_SCENE': {'precision': 0.6387665198237885, 'recall': 0.69377990430622, 'f1': 0.665137614678899, 'number': 209}, 'eval_overall_precision': 0.7055232558139535, 'eval_overall_recall': 0.7900390625, 'eval_overall_f1': 0.7453931203931203, 'eval_overall_accuracy': 0.9952677075577067, 'eval_runtime': 57.3126, 'eval_samples_per_second': 23.433, 'eval_steps_per_second': 1.466, 'epoch': 2.0}\r\n",
      " 67%|██████████████████████████             | 1344/2016 [45:29<20:59,  1.87s/it]\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:56<00:00,  1.72it/s]\u001b[A\r\n",
      " 67%|████████████████████████▋            | 1348/2016 [45:33<1:18:34,  7.06s/it]Trainer is attempting to log a value of \"{'precision': 0.5388127853881278, 'recall': 0.6327077747989276, 'f1': 0.5819975339087545, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7973856209150327, 'recall': 0.7922077922077922, 'f1': 0.7947882736156352, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7170263788968825, 'recall': 0.791005291005291, 'f1': 0.7522012578616352, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7492447129909365, 'recall': 0.8406779661016949, 'f1': 0.792332268370607, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6918238993710691, 'recall': 0.8906882591093117, 'f1': 0.7787610619469028, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7931034482758621, 'recall': 0.7615894039735099, 'f1': 0.777027027027027, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8038461538461539, 'recall': 0.8989247311827957, 'f1': 0.8487309644670051, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7237851662404092, 'recall': 0.771117166212534, 'f1': 0.7467018469656993, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7671232876712328, 'recall': 0.7759815242494227, 'f1': 0.7715269804822042, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6540084388185654, 'recall': 0.7416267942583732, 'f1': 0.695067264573991, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.015412183478474617, 'eval_ADDRESS': {'precision': 0.5388127853881278, 'recall': 0.6327077747989276, 'f1': 0.5819975339087545, 'number': 373}, 'eval_BOOK': {'precision': 0.7973856209150327, 'recall': 0.7922077922077922, 'f1': 0.7947882736156352, 'number': 154}, 'eval_COMPANY': {'precision': 0.7170263788968825, 'recall': 0.791005291005291, 'f1': 0.7522012578616352, 'number': 378}, 'eval_GAME': {'precision': 0.7492447129909365, 'recall': 0.8406779661016949, 'f1': 0.792332268370607, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.6918238993710691, 'recall': 0.8906882591093117, 'f1': 0.7787610619469028, 'number': 247}, 'eval_MOVIE': {'precision': 0.7931034482758621, 'recall': 0.7615894039735099, 'f1': 0.777027027027027, 'number': 151}, 'eval_NAME': {'precision': 0.8038461538461539, 'recall': 0.8989247311827957, 'f1': 0.8487309644670051, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.7237851662404092, 'recall': 0.771117166212534, 'f1': 0.7467018469656993, 'number': 367}, 'eval_POSITION': {'precision': 0.7671232876712328, 'recall': 0.7759815242494227, 'f1': 0.7715269804822042, 'number': 433}, 'eval_SCENE': {'precision': 0.6540084388185654, 'recall': 0.7416267942583732, 'f1': 0.695067264573991, 'number': 209}, 'eval_overall_precision': 0.717827626918536, 'eval_overall_recall': 0.7916666666666666, 'eval_overall_f1': 0.7529411764705883, 'eval_overall_accuracy': 0.9954596751675354, 'eval_runtime': 55.559, 'eval_samples_per_second': 24.173, 'eval_steps_per_second': 1.512, 'epoch': 2.0}\r\n",
      " 67%|██████████████████████████             | 1344/2016 [45:33<20:24,  1.82s/it]\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:54<00:00,  3.35it/s]\u001b[A\r\n",
      "{'loss': 0.0108, 'grad_norm': 17865.447265625, 'learning_rate': 1.3491649269311067e-05, 'epoch': 2.23}\r\n",
      " 74%|████████████████████████████▉          | 1498/2016 [50:34<12:49,  1.49s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.011, 'grad_norm': 12585.623046875, 'learning_rate': 1.3491649269311067e-05, 'epoch': 2.23}\r\n",
      " 75%|█████████████████████████████          | 1505/2016 [50:41<12:16,  1.44s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.0072, 'grad_norm': 13677.3134765625, 'learning_rate': 4.4363256784968686e-07, 'epoch': 2.98}\r\n",
      " 99%|████████████████████████████████████▋| 1996/2016 [1:06:57<00:29,  1.46s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.0072, 'grad_norm': 8887.009765625, 'learning_rate': 4.4363256784968686e-07, 'epoch': 2.98}\r\n",
      "100%|████████████████████████████████████▊| 2008/2016 [1:07:09<00:10,  1.27s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "100%|████████████████████████████████████▊| 2009/2016 [1:07:25<00:11,  1.71s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "100%|████████████████████████████████████▉| 2010/2016 [1:07:27<00:09,  1.54s/it]\r\n",
      "  0%|                                                    | 0/84 [00:00<?, ?it/s]\u001b[A\r\n",
      "  2%|█                                           | 2/84 [00:00<00:29,  2.81it/s]\u001b[A\r\n",
      "100%|████████████████████████████████████▉| 2011/2016 [1:07:28<00:08,  1.63s/it]\r\n",
      "  5%|██                                          | 4/84 [00:01<00:39,  2.01it/s]\u001b[A\r\n",
      "  6%|██▌                                         | 5/84 [00:02<00:42,  1.85it/s]\u001b[A\r\n",
      "100%|████████████████████████████████████▉| 2012/2016 [1:07:30<00:06,  1.70s/it]\r\n",
      "  8%|███▋                                        | 7/84 [00:03<00:45,  1.70it/s]\u001b[A\r\n",
      " 10%|████▏                                       | 8/84 [00:04<00:45,  1.67it/s]\u001b[A\r\n",
      "100%|████████████████████████████████████▉| 2013/2016 [1:07:32<00:05,  1.74s/it]\r\n",
      " 12%|█████                                      | 10/84 [00:05<00:46,  1.60it/s]\u001b[A\r\n",
      " 13%|█████▋                                     | 11/84 [00:06<00:45,  1.59it/s]\u001b[A\r\n",
      "100%|████████████████████████████████████▉| 2014/2016 [1:07:34<00:03,  1.82s/it]\r\n",
      " 15%|██████▋                                    | 13/84 [00:07<00:42,  1.68it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 14/84 [00:08<00:43,  1.60it/s]\u001b[A\r\n",
      "100%|████████████████████████████████████▉| 2015/2016 [1:07:36<00:01,  1.83s/it]\r\n",
      " 19%|████████▏                                  | 16/84 [00:09<00:40,  1.67it/s]\u001b[A\r\n",
      " 20%|████████▋                                  | 17/84 [00:10<00:40,  1.64it/s]\u001b[A\r\n",
      "100%|█████████████████████████████████████| 2016/2016 [1:07:37<00:00,  1.73s/it]\r\n",
      " 23%|█████████▋                                 | 19/84 [00:10<00:34,  1.90it/s]\u001b[A\r\n",
      " 24%|██████████▏                                | 20/84 [00:11<00:29,  2.19it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 21/84 [00:11<00:25,  2.45it/s]\u001b[A\r\n",
      " 26%|███████████▎                               | 22/84 [00:11<00:23,  2.61it/s]\u001b[A\r\n",
      " 27%|███████████▊                               | 23/84 [00:12<00:21,  2.80it/s]\u001b[A\r\n",
      " 29%|████████████▎                              | 24/84 [00:12<00:20,  2.96it/s]\u001b[A\r\n",
      " 30%|████████████▊                              | 25/84 [00:12<00:19,  3.07it/s]\u001b[A\r\n",
      " 31%|█████████████▎                             | 26/84 [00:13<00:18,  3.16it/s]\u001b[A\r\n",
      " 32%|█████████████▊                             | 27/84 [00:13<00:17,  3.23it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 28/84 [00:13<00:17,  3.26it/s]\u001b[A\r\n",
      " 35%|██████████████▊                            | 29/84 [00:13<00:16,  3.33it/s]\u001b[A\r\n",
      " 36%|███████████████▎                           | 30/84 [00:14<00:16,  3.26it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "\r\n",
      "  0%|                                                    | 0/84 [00:00<?, ?it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 31/84 [00:14<00:21,  2.43it/s]\u001b[A\r\n",
      "  2%|█                                           | 2/84 [00:00<00:23,  3.48it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 32/84 [00:15<00:24,  2.15it/s]\u001b[A\r\n",
      "  4%|█▌                                          | 3/84 [00:01<00:33,  2.44it/s]\u001b[A\r\n",
      " 39%|████████████████▉                          | 33/84 [00:16<00:25,  2.02it/s]\u001b[A\r\n",
      "  5%|██                                          | 4/84 [00:01<00:37,  2.13it/s]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 34/84 [00:16<00:26,  1.92it/s]\u001b[A\r\n",
      "  6%|██▌                                         | 5/84 [00:02<00:39,  1.99it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 35/84 [00:17<00:26,  1.85it/s]\u001b[A\r\n",
      "  7%|███▏                                        | 6/84 [00:02<00:41,  1.90it/s]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 36/84 [00:17<00:26,  1.81it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 7/84 [00:03<00:41,  1.85it/s]\u001b[A\r\n",
      " 44%|██████████████████▉                        | 37/84 [00:18<00:26,  1.79it/s]\u001b[A\r\n",
      " 10%|████▏                                       | 8/84 [00:04<00:41,  1.82it/s]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 38/84 [00:18<00:26,  1.77it/s]\u001b[A\r\n",
      " 11%|████▋                                       | 9/84 [00:04<00:41,  1.80it/s]\u001b[A\r\n",
      " 46%|███████████████████▉                       | 39/84 [00:19<00:25,  1.76it/s]\u001b[A\r\n",
      " 12%|█████                                      | 10/84 [00:05<00:41,  1.78it/s]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 40/84 [00:20<00:25,  1.74it/s]\u001b[A\r\n",
      " 13%|█████▋                                     | 11/84 [00:05<00:41,  1.77it/s]\u001b[A\r\n",
      " 49%|████████████████████▉                      | 41/84 [00:20<00:24,  1.75it/s]\u001b[A\r\n",
      " 14%|██████▏                                    | 12/84 [00:06<00:40,  1.76it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 42/84 [00:21<00:24,  1.75it/s]\u001b[A\r\n",
      " 15%|██████▋                                    | 13/84 [00:06<00:40,  1.75it/s]\u001b[A\r\n",
      " 51%|██████████████████████                     | 43/84 [00:21<00:23,  1.75it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 14/84 [00:07<00:39,  1.76it/s]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 44/84 [00:22<00:23,  1.73it/s]\u001b[A\r\n",
      " 18%|███████▋                                   | 15/84 [00:08<00:39,  1.74it/s]\u001b[A\r\n",
      " 54%|███████████████████████                    | 45/84 [00:23<00:22,  1.74it/s]\u001b[A\r\n",
      " 19%|████████▏                                  | 16/84 [00:08<00:39,  1.74it/s]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 46/84 [00:23<00:21,  1.74it/s]\u001b[A\r\n",
      " 20%|████████▋                                  | 17/84 [00:09<00:38,  1.73it/s]\u001b[A\r\n",
      " 56%|████████████████████████                   | 47/84 [00:24<00:21,  1.74it/s]\u001b[A\r\n",
      " 21%|█████████▏                                 | 18/84 [00:09<00:37,  1.74it/s]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 48/84 [00:24<00:20,  1.74it/s]\u001b[A\r\n",
      " 23%|█████████▋                                 | 19/84 [00:10<00:37,  1.73it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 49/84 [00:25<00:20,  1.74it/s]\u001b[A\r\n",
      " 24%|██████████▏                                | 20/84 [00:10<00:34,  1.84it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 21/84 [00:11<00:32,  1.96it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 50/84 [00:26<00:22,  1.53it/s]\u001b[A\r\n",
      " 26%|███████████▎                               | 22/84 [00:11<00:32,  1.89it/s]\u001b[A\r\n",
      " 61%|██████████████████████████                 | 51/84 [00:26<00:20,  1.58it/s]\u001b[A\r\n",
      " 27%|███████████▊                               | 23/84 [00:12<00:32,  1.85it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 52/84 [00:27<00:19,  1.63it/s]\u001b[A\r\n",
      " 29%|████████████▎                              | 24/84 [00:12<00:33,  1.81it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 53/84 [00:27<00:18,  1.64it/s]\u001b[A\r\n",
      " 30%|████████████▊                              | 25/84 [00:13<00:32,  1.80it/s]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 54/84 [00:28<00:17,  1.67it/s]\u001b[A\r\n",
      " 31%|█████████████▎                             | 26/84 [00:14<00:32,  1.79it/s]\u001b[A\r\n",
      " 65%|████████████████████████████▏              | 55/84 [00:29<00:17,  1.68it/s]\u001b[A\r\n",
      " 32%|█████████████▊                             | 27/84 [00:14<00:32,  1.77it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 56/84 [00:29<00:16,  1.68it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 28/84 [00:15<00:31,  1.76it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▏             | 57/84 [00:30<00:15,  1.70it/s]\u001b[A\r\n",
      " 35%|██████████████▊                            | 29/84 [00:15<00:30,  1.78it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 58/84 [00:30<00:15,  1.71it/s]\u001b[A\r\n",
      " 36%|███████████████▎                           | 30/84 [00:16<00:30,  1.75it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████▏            | 59/84 [00:31<00:14,  1.72it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 31/84 [00:16<00:30,  1.74it/s]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 60/84 [00:31<00:13,  1.73it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 32/84 [00:17<00:29,  1.74it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▏           | 61/84 [00:32<00:13,  1.73it/s]\u001b[A\r\n",
      " 39%|████████████████▉                          | 33/84 [00:18<00:29,  1.74it/s]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 62/84 [00:33<00:12,  1.74it/s]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 34/84 [00:18<00:28,  1.73it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 63/84 [00:33<00:12,  1.74it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 35/84 [00:19<00:28,  1.74it/s]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 64/84 [00:34<00:11,  1.74it/s]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 36/84 [00:19<00:27,  1.75it/s]\u001b[A\r\n",
      " 77%|█████████████████████████████████▎         | 65/84 [00:34<00:10,  1.74it/s]\u001b[A\r\n",
      " 44%|██████████████████▉                        | 37/84 [00:20<00:27,  1.74it/s]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 66/84 [00:35<00:10,  1.74it/s]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 38/84 [00:20<00:26,  1.74it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▎        | 67/84 [00:35<00:09,  1.73it/s]\u001b[A\r\n",
      " 46%|███████████████████▉                       | 39/84 [00:21<00:25,  1.74it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 68/84 [00:36<00:09,  1.74it/s]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 40/84 [00:22<00:25,  1.74it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████▎       | 69/84 [00:37<00:08,  1.74it/s]\u001b[A\r\n",
      " 49%|████████████████████▉                      | 41/84 [00:22<00:24,  1.76it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 70/84 [00:37<00:08,  1.73it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 42/84 [00:23<00:24,  1.74it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▎      | 71/84 [00:38<00:07,  1.74it/s]\u001b[A\r\n",
      " 51%|██████████████████████                     | 43/84 [00:23<00:23,  1.74it/s]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 72/84 [00:38<00:06,  1.74it/s]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 44/84 [00:24<00:22,  1.74it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 73/84 [00:39<00:06,  1.75it/s]\u001b[A\r\n",
      " 54%|███████████████████████                    | 45/84 [00:25<00:22,  1.73it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 74/84 [00:39<00:05,  1.75it/s]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 46/84 [00:25<00:21,  1.73it/s]\u001b[A\r\n",
      " 89%|██████████████████████████████████████▍    | 75/84 [00:40<00:05,  1.74it/s]\u001b[A\r\n",
      " 56%|████████████████████████                   | 47/84 [00:26<00:21,  1.74it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 76/84 [00:41<00:04,  1.73it/s]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 48/84 [00:26<00:20,  1.74it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 77/84 [00:41<00:04,  1.73it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 49/84 [00:27<00:20,  1.74it/s]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 78/84 [00:42<00:03,  1.75it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 50/84 [00:27<00:19,  1.73it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▍  | 79/84 [00:42<00:02,  1.75it/s]\u001b[A\r\n",
      " 61%|██████████████████████████                 | 51/84 [00:28<00:18,  1.74it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 80/84 [00:43<00:02,  1.74it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 52/84 [00:29<00:18,  1.74it/s]\u001b[A\r\n",
      " 96%|█████████████████████████████████████████▍ | 81/84 [00:44<00:01,  1.74it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 53/84 [00:29<00:17,  1.74it/s]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 82/84 [00:44<00:01,  1.74it/s]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 54/84 [00:30<00:17,  1.74it/s]\u001b[A\r\n",
      " 99%|██████████████████████████████████████████▍| 83/84 [00:45<00:00,  1.74it/s]\u001b[A\r\n",
      " 65%|████████████████████████████▏              | 55/84 [00:30<00:16,  1.72it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:45<00:00,  1.75it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 56/84 [00:31<00:14,  1.87it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▏             | 57/84 [00:31<00:12,  2.17it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 58/84 [00:31<00:10,  2.44it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████▏            | 59/84 [00:32<00:09,  2.68it/s]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 60/84 [00:32<00:08,  2.86it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▏           | 61/84 [00:32<00:07,  2.96it/s]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 62/84 [00:32<00:07,  3.07it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 63/84 [00:33<00:06,  3.17it/s]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 64/84 [00:33<00:06,  3.23it/s]\u001b[A\r\n",
      " 77%|█████████████████████████████████▎         | 65/84 [00:33<00:05,  3.29it/s]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 66/84 [00:34<00:05,  3.34it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▎        | 67/84 [00:34<00:05,  3.36it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 68/84 [00:34<00:04,  3.41it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████▎       | 69/84 [00:35<00:04,  3.38it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 70/84 [00:35<00:04,  3.39it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▎      | 71/84 [00:35<00:03,  3.39it/s]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 72/84 [00:35<00:03,  3.41it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 73/84 [00:36<00:03,  3.40it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 74/84 [00:36<00:02,  3.43it/s]\u001b[A\r\n",
      " 89%|██████████████████████████████████████▍    | 75/84 [00:36<00:02,  3.42it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 76/84 [00:37<00:02,  3.42it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 77/84 [00:37<00:02,  3.46it/s]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 78/84 [00:37<00:01,  3.45it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▍  | 79/84 [00:37<00:01,  3.43it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 80/84 [00:38<00:01,  3.42it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.5847255369928401, 'recall': 0.6568364611260054, 'f1': 0.6186868686868687, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7592592592592593, 'recall': 0.7987012987012987, 'f1': 0.7784810126582278, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7292161520190024, 'recall': 0.8121693121693122, 'f1': 0.7684605757196495, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7514792899408284, 'recall': 0.8610169491525423, 'f1': 0.8025276461295419, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.754325259515571, 'recall': 0.8825910931174089, 'f1': 0.8134328358208954, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8079470198675497, 'recall': 0.8079470198675497, 'f1': 0.8079470198675497, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8243512974051896, 'recall': 0.8881720430107527, 'f1': 0.855072463768116, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7139364303178484, 'recall': 0.7956403269754768, 'f1': 0.7525773195876287, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7402061855670103, 'recall': 0.8290993071593533, 'f1': 0.7821350762527233, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6375545851528385, 'recall': 0.6985645933014354, 'f1': 0.6666666666666667, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.01631040871143341, 'eval_ADDRESS': {'precision': 0.5847255369928401, 'recall': 0.6568364611260054, 'f1': 0.6186868686868687, 'number': 373}, 'eval_BOOK': {'precision': 0.7592592592592593, 'recall': 0.7987012987012987, 'f1': 0.7784810126582278, 'number': 154}, 'eval_COMPANY': {'precision': 0.7292161520190024, 'recall': 0.8121693121693122, 'f1': 0.7684605757196495, 'number': 378}, 'eval_GAME': {'precision': 0.7514792899408284, 'recall': 0.8610169491525423, 'f1': 0.8025276461295419, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.754325259515571, 'recall': 0.8825910931174089, 'f1': 0.8134328358208954, 'number': 247}, 'eval_MOVIE': {'precision': 0.8079470198675497, 'recall': 0.8079470198675497, 'f1': 0.8079470198675497, 'number': 151}, 'eval_NAME': {'precision': 0.8243512974051896, 'recall': 0.8881720430107527, 'f1': 0.855072463768116, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.7139364303178484, 'recall': 0.7956403269754768, 'f1': 0.7525773195876287, 'number': 367}, 'eval_POSITION': {'precision': 0.7402061855670103, 'recall': 0.8290993071593533, 'f1': 0.7821350762527233, 'number': 433}, 'eval_SCENE': {'precision': 0.6375545851528385, 'recall': 0.6985645933014354, 'f1': 0.6666666666666667, 'number': 209}, 'eval_overall_precision': 0.7282608695652174, 'eval_overall_recall': 0.8069661458333334, 'eval_overall_f1': 0.7655960469425571, 'eval_overall_accuracy': 0.9956894545793, 'eval_runtime': 53.5161, 'eval_samples_per_second': 25.095, 'eval_steps_per_second': 1.57, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████| 2016/2016 [1:08:20<00:00,  1.83s/it]\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:52<00:00,  1.75it/s]\u001b[A\r\n",
      "{'train_runtime': 4100.2293, 'train_samples_per_second': 7.864, 'train_steps_per_second': 0.492, 'train_loss': 0.037563078792854435, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████| 2016/2016 [1:08:20<00:00,  2.03s/it]\r\n",
      "\r\n",
      " 96%|█████████████████████████████████████████▍ | 81/84 [00:38<00:00,  3.42it/s]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 82/84 [00:38<00:00,  3.41it/s]\u001b[A\r\n",
      " 99%|██████████████████████████████████████████▍| 83/84 [00:39<00:00,  3.41it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:39<00:00,  3.47it/s]\u001b[A[rank0]:[W730 08:19:20.493289858 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5769230769230769, 'recall': 0.6434316353887399, 'f1': 0.6083650190114068, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.775, 'recall': 0.8051948051948052, 'f1': 0.7898089171974523, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7554479418886199, 'recall': 0.8253968253968254, 'f1': 0.788874841972187, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7319884726224783, 'recall': 0.8610169491525423, 'f1': 0.7912772585669782, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7403508771929824, 'recall': 0.854251012145749, 'f1': 0.7932330827067668, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7516339869281046, 'recall': 0.7615894039735099, 'f1': 0.756578947368421, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8357289527720739, 'recall': 0.875268817204301, 'f1': 0.8550420168067226, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7060240963855422, 'recall': 0.7983651226158038, 'f1': 0.7493606138107416, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7542735042735043, 'recall': 0.815242494226328, 'f1': 0.7835738068812431, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6434782608695652, 'recall': 0.7081339712918661, 'f1': 0.6742596810933941, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.01610131375491619, 'eval_ADDRESS': {'precision': 0.5769230769230769, 'recall': 0.6434316353887399, 'f1': 0.6083650190114068, 'number': 373}, 'eval_BOOK': {'precision': 0.775, 'recall': 0.8051948051948052, 'f1': 0.7898089171974523, 'number': 154}, 'eval_COMPANY': {'precision': 0.7554479418886199, 'recall': 0.8253968253968254, 'f1': 0.788874841972187, 'number': 378}, 'eval_GAME': {'precision': 0.7319884726224783, 'recall': 0.8610169491525423, 'f1': 0.7912772585669782, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.7403508771929824, 'recall': 0.854251012145749, 'f1': 0.7932330827067668, 'number': 247}, 'eval_MOVIE': {'precision': 0.7516339869281046, 'recall': 0.7615894039735099, 'f1': 0.756578947368421, 'number': 151}, 'eval_NAME': {'precision': 0.8357289527720739, 'recall': 0.875268817204301, 'f1': 0.8550420168067226, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.7060240963855422, 'recall': 0.7983651226158038, 'f1': 0.7493606138107416, 'number': 367}, 'eval_POSITION': {'precision': 0.7542735042735043, 'recall': 0.815242494226328, 'f1': 0.7835738068812431, 'number': 433}, 'eval_SCENE': {'precision': 0.6434782608695652, 'recall': 0.7081339712918661, 'f1': 0.6742596810933941, 'number': 209}, 'eval_overall_precision': 0.7282157676348547, 'eval_overall_recall': 0.7998046875, 'eval_overall_f1': 0.7623332299100216, 'eval_overall_accuracy': 0.9956167395755771, 'eval_runtime': 46.7618, 'eval_samples_per_second': 28.72, 'eval_steps_per_second': 1.796, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████| 2016/2016 [1:08:28<00:00,  1.73s/it]\r\n",
      "100%|███████████████████████████████████████████| 84/84 [00:46<00:00,  3.47it/s]\u001b[A\r\n",
      "{'train_runtime': 4108.197, 'train_samples_per_second': 7.849, 'train_steps_per_second': 0.491, 'train_loss': 0.036584902096480604, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████| 2016/2016 [1:08:28<00:00,  2.04s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!python hw_02_ner_ddp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f9353a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T08:19:31.085740Z",
     "iopub.status.busy": "2025-07-30T08:19:31.085452Z",
     "iopub.status.idle": "2025-07-30T08:19:40.688427Z",
     "shell.execute_reply": "2025-07-30T08:19:40.687482Z"
    },
    "papermill": {
     "duration": 9.837811,
     "end_time": "2025-07-30T08:19:40.689679",
     "exception": false,
     "start_time": "2025-07-30T08:19:30.851868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 08:19:37.114368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753863577.139198      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753863577.146581      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张: O\n",
      "艺: B-ADDRESS\n",
      "谋: I-ADDRESS\n",
      "导: I-ADDRESS\n",
      "演: B-NAME\n",
      "的: I-NAME\n",
      "电: O\n",
      "影: O\n",
      "《: O\n",
      "活: B-GAME\n",
      "着: I-GAME\n",
      "》: I-GAME\n",
      "改: I-GAME\n",
      "编: O\n",
      "自: O\n",
      "余: O\n",
      "华: B-ADDRESS\n",
      "的: I-ADDRESS\n",
      "小: O\n",
      "说: O\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "def predict_entities(text, model, tokenizer, id2label, device):\n",
    "    # 准备输入并移动到指定设备\n",
    "    inputs = tokenizer(\n",
    "        list(text), \n",
    "        is_split_into_words=True, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True\n",
    "    ).to(device)  # 将输入数据移至GPU/CPU\n",
    "    \n",
    "    # 推理\n",
    "    with torch.no_grad():  # 禁用梯度计算，节省内存并加速\n",
    "        outputs = model(** inputs)\n",
    "    \n",
    "    # 获取预测结果\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)\n",
    "    predicted_labels = [id2label[p.item()] for p in predictions[0]]\n",
    "    \n",
    "    # 组合结果\n",
    "    result = list(zip(list(text), predicted_labels))\n",
    "    return result\n",
    "\n",
    "# 检查是否有可用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 加载模型和tokenizer\n",
    "model_path = \"/kaggle/output/ner_final_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "# 将模型移动到GPU\n",
    "model = model.to(device)\n",
    "# 设置为评估模式（关闭dropout等训练特定层）\n",
    "model.eval()\n",
    "\n",
    "# 准备标签映射\n",
    "entites = ['O'] + list({'movie', 'name', 'game', 'address', 'position', \n",
    "                        'company', 'scene', 'book', 'organization', 'government'})\n",
    "tags = ['O']\n",
    "for entity in entites[1:]:\n",
    "    tags.append('B-' + entity.upper())\n",
    "    tags.append('I-' + entity.upper())\n",
    "id2label = {i: tag for i, tag in enumerate(tags)}\n",
    "\n",
    "# 测试文本\n",
    "test_text = \"张艺谋导演的电影《活着》改编自余华的小说\"\n",
    "\n",
    "# 预测\n",
    "results = predict_entities(test_text, model, tokenizer, id2label, device)\n",
    "\n",
    "# 打印结果\n",
    "for char, label in results:\n",
    "    print(f\"{char}: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4197.030211,
   "end_time": "2025-07-30T08:19:44.086221",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-30T07:09:47.056010",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
